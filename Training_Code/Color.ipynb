{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxygTPKU3lBW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "FPcKhPcw9UAo",
        "outputId": "0fa879a5-245c-4bd0-a9fe-7e4bc88bac1b"
      },
      "outputs": [],
      "source": [
        "# 1. Mount Google Drive to save model later\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Upload kaggle.json (your Kaggle API token)\n",
        "from google.colab import files\n",
        "print(\"Upload your kaggle.json API token now:\")\n",
        "files.upload()  # Upload kaggle.json here\n",
        "\n",
        "# 3. Setup Kaggle API\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 4. Download the dataset you shared\n",
        "!kaggle datasets download -d landrykezebou/vcor-vehicle-color-recognition-dataset\n",
        "\n",
        "# 5. Unzip it\n",
        "!unzip -q vcor-vehicle-color-recognition-dataset.zip -d ./vcor_dataset\n",
        "\n",
        "# 6. Check folder structure and set train/val paths dynamically\n",
        "import os\n",
        "\n",
        "base_dir = './vcor_dataset'\n",
        "train_path, val_path = None, None\n",
        "\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    if 'train' in dirs:\n",
        "        train_path = os.path.join(root, 'train')\n",
        "    if 'val' in dirs:\n",
        "        val_path = os.path.join(root, 'val')\n",
        "\n",
        "print(f\"‚úÖ Train path detected: {train_path}\")\n",
        "print(f\"‚úÖ Val path detected: {val_path}\")\n",
        "\n",
        "if not train_path or not val_path:\n",
        "    raise Exception(\"‚ùå Train or val folders not found. Please check the extracted folder structure.\")\n",
        "\n",
        "# 7. Install required packages (if needed)\n",
        "!pip install -q torch torchvision\n",
        "\n",
        "# 8. Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 9. Define data transforms\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# 10. Load datasets\n",
        "train_dataset = datasets.ImageFolder(train_path, transform=transform_train)\n",
        "val_dataset = datasets.ImageFolder(val_path, transform=transform_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(f\"‚úÖ Number of classes: {num_classes}\")\n",
        "print(f\"‚úÖ Classes: {train_dataset.classes}\")\n",
        "\n",
        "# 11. Load pretrained ResNet50 and modify final layer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# 12. Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# 13. Training loop with saving after each epoch\n",
        "num_epochs = 5  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    print(f\"‚úÖ Epoch {epoch+1}/{num_epochs} ‚Äî Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "    # üîµ Save model after each epoch\n",
        "    epoch_save_path = f'/content/drive/MyDrive/vcor_resnet50_epoch{epoch+1}.pth'\n",
        "    torch.save(model.state_dict(), epoch_save_path)\n",
        "    print(f\"üíæ Model saved after epoch {epoch+1} to {epoch_save_path}\")\n",
        "\n",
        "# 14. Save final trained model to Google Drive\n",
        "final_save_path = '/content/drive/MyDrive/vcor_finetuned_resnet50_final.pth'\n",
        "torch.save(model.state_dict(), final_save_path)\n",
        "print(f\"‚úÖ Final PyTorch model saved to {final_save_path}\")\n",
        "\n",
        "# 15. Convert to TorchScript for Raspberry Pi deployment\n",
        "example = torch.rand(1, 3, 224, 224).to(device)\n",
        "traced_script_module = torch.jit.trace(model, example)\n",
        "torchscript_path = '/content/drive/MyDrive/vcor_finetuned_scripted.pt'\n",
        "traced_script_module.save(torchscript_path)\n",
        "print(f\"‚úÖ TorchScript model saved to {torchscript_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "anIxatZyYr96",
        "outputId": "b2669530-c30a-4f86-9456-960dc432299c"
      },
      "outputs": [],
      "source": [
        "# Install Kaggle if needed\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload kaggle.json for Kaggle API authentication\n",
        "from google.colab import files\n",
        "files.upload()  # Upload your kaggle.json here\n",
        "\n",
        "# Setup Kaggle API credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d landrykezebou/vcor-vehicle-color-recognition-dataset\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip -q vcor-vehicle-color-recognition-dataset.zip -d ./vcor_dataset\n",
        "\n",
        "# Check folder structure\n",
        "!ls ./vcor_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "wbLH1qKojmbD",
        "outputId": "a2978bca-f4a9-4470-de32-55b0b4dec7b5"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# üöÄ FULL INFERENCE SCRIPT USING TRAINING DATA CLASSES\n",
        "# ===============================\n",
        "\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, datasets\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive, files\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive (if not already mounted)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define dataset folder (adjust if needed)\n",
        "train_path = '/content/vcor_dataset/train'  # Change to your actual train folder path\n",
        "\n",
        "# 3. Load training dataset to get classes\n",
        "train_dataset = datasets.ImageFolder(train_path)\n",
        "colour_labels = train_dataset.classes\n",
        "num_classes = len(colour_labels)\n",
        "\n",
        "print(f\"‚úÖ Classes used in training: {colour_labels}\")\n",
        "print(f\"‚úÖ Number of classes: {num_classes}\")\n",
        "\n",
        "# 4. Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ Using device: {device}\")\n",
        "\n",
        "# 5. Upload an image for testing\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Uploaded image: {image_path}\")\n",
        "\n",
        "# 6. Define preprocessing transform (match training preprocessing)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Imagenet normalization\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 7. Load and preprocess the image\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "input_tensor = test_transform(image).unsqueeze(0).to(device)  # Add batch dim\n",
        "\n",
        "# 8. Load model architecture and weights\n",
        "model = models.resnet50(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "model_path = '/content/drive/MyDrive/vcor_finetuned_resnet50_final.pth'  # Change if needed\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# 9. Predict with confidence\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_tensor)\n",
        "    probs = F.softmax(outputs, dim=1)\n",
        "    top_prob, top_class = torch.max(probs, 1)\n",
        "\n",
        "predicted_colour = colour_labels[top_class.item()]\n",
        "confidence = top_prob.item() * 100\n",
        "\n",
        "print(f\"üé® Predicted car colour: {predicted_colour} ({confidence:.2f}% confidence)\")\n",
        "\n",
        "# 10. Show image with prediction title\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Predicted Colour: {predicted_colour} ({confidence:.2f}%)\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "07R9lgtsgsCk",
        "outputId": "1ae50e47-56c5-47b9-e921-df6e5875d9c0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "# Save the class labels from your training dataset\n",
        "with open(\"vcor_classes.json\", \"w\") as f:\n",
        "    json.dump(train_dataset.classes, f)\n",
        "\n",
        "# Download the file to your local machine\n",
        "files.download(\"vcor_classes.json\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
