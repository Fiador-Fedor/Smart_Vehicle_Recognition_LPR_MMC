{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b93aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ca7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_contours_into_rows(rects, threshold=10):\n",
    "    if not rects:\n",
    "        return []\n",
    "    \n",
    "    # Sort rectangles by y-coordinate (top edge)\n",
    "    sorted_rects = sorted(rects, key=lambda r: r[1])\n",
    "    \n",
    "    rows = []\n",
    "    current_row = [sorted_rects[0]]\n",
    "    for rect in sorted_rects[1:]:\n",
    "        # If the y-coordinate difference is small, add to the current row\n",
    "        if rect[1] - current_row[-1][1] < threshold:\n",
    "            current_row.append(rect)\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [rect]\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "    \n",
    "    # Sort each row by x-coordinate (left to right)\n",
    "    for row in rows:\n",
    "        row.sort(key=lambda r: r[0])\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7989be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find characters in the resulting images\n",
    "\n",
    "\n",
    "def segment_characters(image):\n",
    "    # Preprocess cropped license plate image\n",
    "    img_lp = cv2.resize(image, (333, 75))\n",
    "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
    "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
    "\n",
    "    # Make borders white\n",
    "    img_binary_lp[0:3, :] = 255\n",
    "    img_binary_lp[:, 0:3] = 255\n",
    "    img_binary_lp[72:75, :] = 255\n",
    "    img_binary_lp[:, 330:333] = 255\n",
    "\n",
    "    # Show binary image for debugging\n",
    "    plt.imshow(img_binary_lp, cmap='gray')\n",
    "    plt.title('Binary License Plate')\n",
    "    plt.show()\n",
    "\n",
    "    # Find all potential character contours\n",
    "    cntrs, _ = cv2.findContours(img_binary_lp.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
    "    \n",
    "    rects = []\n",
    "    for cntr in cntrs:\n",
    "        x, y, w, h = cv2.boundingRect(cntr)\n",
    "        # Relaxed dimensions to capture characters from both rows\n",
    "        if 5 < w < 50 and 10 < h < 60:\n",
    "            rects.append((x, y, w, h))\n",
    "    \n",
    "    # Group contours into rows\n",
    "    rows = group_contours_into_rows(rects, threshold=10)\n",
    "    \n",
    "    # Visualize detected characters by row\n",
    "    ii = img_lp.copy()\n",
    "    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]  # Colors for different rows\n",
    "    for i, row in enumerate(rows):\n",
    "        color = colors[i % len(colors)]\n",
    "        for x, y, w, h in row:\n",
    "            cv2.rectangle(ii, (x, y), (x + w, y + h), color, 2)\n",
    "    plt.imshow(cv2.cvtColor(ii, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Detected Characters by Row')\n",
    "    plt.show()\n",
    "    \n",
    "    # Extract character images\n",
    "    char_images = []\n",
    "    for row in rows:\n",
    "        row_chars = []\n",
    "        for x, y, w, h in row:\n",
    "            char = img_binary_lp[y:y+h, x:x+w]\n",
    "            char = cv2.resize(char, (20, 40))\n",
    "            char = cv2.subtract(255, char)\n",
    "            char_copy = np.zeros((44, 24))\n",
    "            char_copy[2:42, 2:22] = char\n",
    "            char_copy[0:2, :] = 0\n",
    "            char_copy[:, 0:2] = 0\n",
    "            char_copy[42:44, :] = 0\n",
    "            char_copy[:, 22:24] = 0\n",
    "            row_chars.append(char_copy)\n",
    "        char_images.extend(row_chars)\n",
    "    \n",
    "    return char_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa71885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = 'plate_crops/img_000029_0.jpg'  # Replace with your image path61,29\n",
    "image = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original')\n",
    "plt.show()\n",
    "\n",
    "char_images = segment_characters(image)\n",
    "\n",
    "# Show all segmented characters\n",
    "for i, char_img in enumerate(char_images):\n",
    "    plt.subplot(1, len(char_images), i + 1)\n",
    "    plt.imshow(char_img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Segmented Characters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620fab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Define the CNN model\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(32, (16,16), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(64, (8,8), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(64, (4,4), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# # Set up data generators\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n",
    "# path = 'data/data'\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     path + '/train',\n",
    "#     target_size=(28,28),\n",
    "#     batch_size=1,\n",
    "#     class_mode='sparse'\n",
    "# )\n",
    "\n",
    "# validation_generator = train_datagen.flow_from_directory(\n",
    "#     path + '/val',\n",
    "#     target_size=(28,28),\n",
    "#     batch_size=1,\n",
    "#     class_mode='sparse'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (uncomment and adjust epochs as needed)\n",
    "model = load_model('final_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert grayscale to 3-channel image\n",
    "def fix_dimension(img):\n",
    "    new_img = np.zeros((28,28,3))\n",
    "    for i in range(3):\n",
    "        new_img[:,:,i] = img\n",
    "    return new_img\n",
    "\n",
    "# Function to predict and display results\n",
    "def show_results(char_list):\n",
    "    dic = {}\n",
    "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    for i, c in enumerate(characters):\n",
    "        dic[i] = c\n",
    "\n",
    "    output = []\n",
    "    for ch in char_list:\n",
    "        img_ = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
    "        img = fix_dimension(img_)\n",
    "        img = img.reshape(1,28,28,3)\n",
    "        y_ = np.argmax(model.predict(img), axis=-1)[0]\n",
    "        character = dic[y_]\n",
    "        output.append(character)\n",
    "    plate_number = ''.join(output)\n",
    "    return plate_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b56388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (uncomment and provide your own char_list)\n",
    "char_list = [char_images[i] for i in range(len(char_images))]\n",
    "plate_number = show_results(char_list)\n",
    "print(plate_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
